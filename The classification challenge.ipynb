{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cross-canvas",
   "metadata": {},
   "source": [
    "# The classification challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-somalia",
   "metadata": {},
   "source": [
    "We have a set of labeled data and we want to build a classifier that takes unlabeled data as input and outputs a label. So how do we construct this classifier? We first need choose a type of classifier and it needs to learn from the already labeled data. For this reason, we call the already labeled data the training data. So let's build our classifier!\n",
    "\n",
    "## The Iris dataset\n",
    "It contains data pertaining to iris flowers in which the features consist of four measurements: petal length, petal width, sepal length, and sepal width. The target variable encodes the species of flower and there are three possibilities: 'versicolor', 'virginica', and 'setosa'. As this is one of the datasets included in scikit-learn, we'll import it from there with from sklearn import datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vocational-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-finland",
   "metadata": {},
   "source": [
    "We then load the dataset with datasets dot load iris and assign the data to a variable iris. Checking out the type of iris, we see that it's a bunch, which is similar to a dictionary in that it contains key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chicken-seattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-processor",
   "metadata": {},
   "source": [
    "Printing the keys, we see that they are the feature names: DESCR, which provides a description of the dataset; the target names; the data, which contains the values features; and the target, which is the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "roman-librarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-conditioning",
   "metadata": {},
   "source": [
    "## K-nearest neighbors(KNN)\n",
    "We'll choose a simple algorithm called K-nearest neighbors. The basic idea of K-nearest neighbors, or KNN, is to predict the label of any data point by looking at the K, for example, 3, closest labeled data points and getting them to vote on what label the unlabeled point should have.Now we're going to fit our very first classifier using scikit-learn! To do so, we first need to import it. To this end, we import KNeighborsClassifier from sklearn dot neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "suburban-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-exercise",
   "metadata": {},
   "source": [
    "We then instantiate our KNeighborsClassifier, set the number of neighbors equal to 6, and assign it to the variable knn. Then we can fit this classifier to our training set, the labeled data. To do so, we apply the method fit to the classifier and pass it two arguments: the features as a NumPy array and the labels, or target, as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suffering-attraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(iris['data'], iris['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-russia",
   "metadata": {},
   "source": [
    "The scikit-learn API requires firstly that you have the data as a NumPy array or pandas DataFrame. It also requires that the features take on continuous values, such as the price of a house, as opposed to categories, such as 'male' or 'female'. It also requires that there are no missing values in the data. . Looking at the shape of iris data, we see that there are 150 observations of four features. Similarly, the target needs to be a single column with the same number of observations as the feature data. We see in this case there are indeed also 150 labels. Also check out what is returned when we fit the classifier: it returns the classifier itself and modifies it to fit it to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "secondary-cornwall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "persistent-republican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['target'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-vector",
   "metadata": {},
   "source": [
    "Now that we have fit our classifier, lets use it to predict on some unlabeled data!. Here we have set of observations, X new. We use the predict method on the classifier and pass it the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "competent-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[5.6, 2.8, 3.9, 1.1], \n",
    "                 [5.7, 2.6, 3.8, 1.3],\n",
    "                 [4.7, 3.2, 1.3, 0.2]])\n",
    "\n",
    "prediction = knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-impression",
   "metadata": {},
   "source": [
    "Once again, the API requires that we pass the data as a NumPy array with features in columns and observations in rows; checking the shape of X new, we see that it has three rows and four columns, that is, three observations and four features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "breathing-register",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-dispatch",
   "metadata": {},
   "source": [
    "Then we would expect calling knn dot predict of X new to return a three-by-one array with a prediction for each observation or row in X new. And indeed it does! It predicts one, which corresponds to 'versicolor' for the first two observations and 0, which corresponds to 'setosa' for the third. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "integrated-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print('Prediction: {}'.format(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
